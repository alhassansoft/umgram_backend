// Simple test script to verify chunked indexing works
import { es } from "./src/lib/es";
import { chunkText } from "./src/services/textChunking";
import { indexDiaryWithChunking, searchChunkedDiaries } from "./src/services/diaryChunkedIndexing";

async function testChunkedIndexing() {
  console.log("üß™ Testing Chunked Indexing System...");
  
  // Create a long test text
  const longText = `Ÿáÿ∞ÿß ŸÜÿµ ÿ∑ŸàŸäŸÑ ÿ¨ÿØÿßŸã Ÿäÿ≠ÿ™ŸàŸä ÿπŸÑŸâ ÿßŸÑÿπÿØŸäÿØ ŸÖŸÜ ÿßŸÑÿ¨ŸÖŸÑ ŸàÿßŸÑŸÅŸÇÿ±ÿßÿ™. `.repeat(100) + 
    `Ÿäÿ™ÿ≠ÿØÿ´ Ÿáÿ∞ÿß ÿßŸÑŸÜÿµ ÿπŸÜ ÿßŸÑÿ≠Ÿäÿßÿ© ÿßŸÑŸäŸàŸÖŸäÿ© ŸàÿßŸÑÿ∞ŸÉÿ±Ÿäÿßÿ™ ÿßŸÑŸÖŸáŸÖÿ©. ` +
    `ŸÜÿ±ŸäÿØ ÿ£ŸÜ ŸÜÿ™ÿ£ŸÉÿØ ŸÖŸÜ ÿ£ŸÜ Ÿáÿ∞ÿß ÿßŸÑŸÜÿµ ÿ≥Ÿäÿ™ŸÖ ÿ™ŸÇÿ≥ŸäŸÖŸá ÿ•ŸÑŸâ ÿ£ÿ¨ÿ≤ÿßÿ° ÿµÿ∫Ÿäÿ±ÿ© ŸÇÿßÿ®ŸÑÿ© ŸÑŸÑÿ®ÿ≠ÿ´. ` +
    `ŸÉŸÑ ÿ¨ÿ≤ÿ° Ÿäÿ¨ÿ® ÿ£ŸÜ ŸäŸÉŸàŸÜ ŸÖÿ≥ÿ™ŸÇŸÑÿßŸã ŸÅŸä ŸÅŸáÿ±ÿ≥ ÿßŸÑÿ®ÿ≠ÿ´. ` +
    `Ÿáÿ∞ÿß Ÿäÿ≠ŸÑ ÿßŸÑŸÖÿ¥ŸÉŸÑÿ© ÿßŸÑÿ™Ÿä ŸÉÿßŸÜÿ™ ÿ™ÿ≠ŸÅÿ∏ ÿßŸÑŸÜÿµŸàÿµ ÿßŸÑÿ∑ŸàŸäŸÑÿ© ÿ®ÿßŸÑŸÉÿßŸÖŸÑ.`;

  console.log(`üìè Original text length: ${longText.length} characters`);
  
  // Test text chunking
  const chunks = chunkText("Test Title", longText);
  console.log(`‚úÇÔ∏è  Text split into ${chunks.length} chunks:`);
  chunks.forEach((chunk, index) => {
    console.log(`   Chunk ${index + 1}: ${chunk.content.length} chars - "${chunk.content.substring(0, 50)}..."`);
  });
  
  // Test indexing if ES is available
  if (es) {
    console.log("üìù Testing diary indexing with chunks...");
    
    const testDiary = {
      id: "test_chunked_diary_" + Date.now(),
      userId: "test_user",
      title: "Test Long Diary Entry",
      content: longText,
      createdAt: new Date(),
      updatedAt: new Date(),
      actions: ["write", "test"],
      entities: ["diary", "system"],
      phrases_en: ["test chunking", "long text"],
      inquiry_en: "testing chunked indexing system"
    };
    
    try {
      // Index the diary with chunking
      await indexDiaryWithChunking(testDiary);
      console.log("‚úÖ Diary indexed successfully with chunks");
      
      // Test search
      const searchQuery = {
        bool: {
          must: [
            {
              multi_match: {
                query: "ŸÜÿµ ÿ∑ŸàŸäŸÑ",
                fields: ["content", "title"],
                type: "best_fields"
              }
            }
          ]
        }
      };
      
      const searchResult = await searchChunkedDiaries(searchQuery, {
        size: 10,
        aggregateChunks: true
      });
      
      console.log(`üîç Search found ${searchResult.hits.length} results`);
      if (searchResult.hits.length > 0) {
        const firstHit = searchResult.hits[0];
        console.log(`   First result ID: ${firstHit._id}`);
        console.log(`   Content length: ${(firstHit._source as any).content?.length || 0} chars`);
        console.log(`   Is aggregated: ${!(firstHit._source as any).isChunk}`);
      }
      
    } catch (error) {
      console.error("‚ùå Test failed:", error);
    }
  } else {
    console.log("‚ö†Ô∏è  Elasticsearch not available, skipping indexing test");
  }
  
  console.log("üéâ Chunked indexing test completed!");
}

// Run test if this file is executed directly
if (require.main === module) {
  testChunkedIndexing().catch(console.error);
}

export { testChunkedIndexing };
